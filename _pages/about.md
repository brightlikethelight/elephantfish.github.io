---
layout: about
title: about
permalink: /
subtitle: Graduate Student in Deep Learning | MIT 6.S898

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <p>MIT CSAIL</p>
    <p>Cambridge, MA 02139</p>

news: true  # includes a list of news items
latest_posts: true  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

## About Me

I am a graduate student at MIT pursuing advanced research in **deep learning and neural network interpretability**. My work focuses on understanding and improving the transparency of large-scale neural networks, with particular emphasis on **vision-language models**, **sparse representations**, and **physics-informed machine learning**.

### Research Interests

My research spans multiple domains of modern deep learning:

**üî¨ Neural Network Interpretability**
- Sparse autoencoders for feature disentanglement in large language models
- Activation patching techniques for understanding CNN decision processes
- Visualization methods for transformer and CLIP model internal representations

**ü§ñ Advanced Neural Architectures**
- Transformer applications across diverse domains ("Transformers as Gamers")
- Vision-language model dynamics and learning processes
- Graph Neural Networks for biological data analysis (scRNA-GNNs)

**‚öôÔ∏è Scientific Machine Learning**
- Physics-Informed Neural Networks (PINNs) for complex system modeling
- Ecological modeling using transformer architectures
- Integration of domain knowledge with deep learning methods

**üéØ Optimization & Control**
- Task-specific data augmentation strategies
- Neural approaches to optimal control problems
- Representation learning for recommendation systems

### Academic Background

**Massachusetts Institute of Technology**  
*Graduate Student, 6.S898 Deep Learning* | 2023  
Focus: Advanced neural network architectures, interpretability methods, and scientific applications

### Research Philosophy

I believe that understanding *how* neural networks work is as important as making them work well. My research combines theoretical investigation with practical implementation, always with an eye toward:

- **Reproducibility**: All research includes complete code and detailed experimental setups
- **Interpretability**: Developing methods to understand neural network decision processes
- **Real-world Impact**: Applying deep learning to meaningful scientific and practical problems
- **Open Science**: Contributing to the broader research community through open-source implementations

### Current Projects

**üîç CLIP Dynamics Analysis**  
Comprehensive investigation of how vision-language models learn multimodal representations, including novel visualization techniques and training dynamics characterization.

**üß† Sparse Autoencoder Development**  
Creating interpretable feature extraction methods for large language models that maintain performance while providing insight into learned representations.

**üåä Physics-Informed Deep Learning**  
Developing neural network approaches that incorporate physical laws and constraints for improved modeling of complex dynamical systems.

**üß¨ Biological Data Analysis**  
Applying Graph Neural Networks to single-cell RNA sequencing data for improved understanding of cellular processes and disease mechanisms.

### Publications & Research Output

- **100+ Research Blog Posts**: Detailed technical investigations across multiple deep learning domains
- **Open Source Contributions**: Complete implementations available on GitHub
- **Academic Presentations**: Research presented at MIT and in academic community forums
- **Collaborative Research**: Working with faculty and peers on cutting-edge deep learning problems

### Technical Expertise

**Programming & Frameworks**
- **Python**: TensorFlow, PyTorch, JAX, scikit-learn
- **Research Tools**: Jupyter, Docker, Git, HPC clusters
- **Web Development**: Jekyll, HTML/CSS, JavaScript
- **Scientific Computing**: NumPy, SciPy, Matplotlib, Pandas

**Machine Learning Specializations**
- **Deep Learning**: CNNs, RNNs, Transformers, Autoencoders
- **Computer Vision**: Image classification, object detection, vision-language models
- **Natural Language Processing**: Language models, text analysis, multimodal systems
- **Scientific ML**: Physics-informed networks, graph neural networks, optimization

### Academic Service & Community

- **Peer Review**: Contributing to academic review processes for course projects
- **Open Source**: Maintaining research code repositories for community use
- **Mentorship**: Supporting undergraduate and fellow graduate students in research
- **Outreach**: Communicating complex research concepts through accessible blog posts

### Recognition & Impact

- **MIT 6.S898 Graduate Course**: Advanced deep learning research and experimentation
- **Research Portfolio**: 100+ documented research investigations across multiple domains
- **Open Science**: All research publicly available with reproducible code and documentation
- **Community Engagement**: Active participation in academic and open-source communities

### Current Research Directions

**Short-term Goals**
- Advancing sparse autoencoder architectures for improved interpretability
- Developing novel visualization techniques for transformer attention mechanisms
- Expanding physics-informed neural network applications to complex systems

**Long-term Vision**
- Contributing to the development of inherently interpretable AI systems
- Bridging the gap between theoretical understanding and practical deep learning applications
- Advancing scientific discovery through intelligent integration of domain knowledge and neural networks

### Collaboration & Opportunities

I am always interested in collaborating on challenging problems at the intersection of deep learning, interpretability, and scientific applications. Current areas of particular interest include:

- **Interpretability Methods**: Novel approaches to understanding neural network decision processes
- **Scientific Applications**: Applying deep learning to physics, biology, and environmental science
- **Multimodal Learning**: Integration of vision, language, and other modalities
- **Academic Research**: Collaboration on publishable research in top-tier conferences and journals

---

*I am committed to advancing both the theoretical understanding and practical applications of deep learning through rigorous research, open science practices, and collaborative engagement with the broader academic community.*